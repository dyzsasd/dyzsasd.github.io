{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns.difference(['ID_code', 'target'])]\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "minor_X = X[y == 1]\n",
    "major_X = X[y == 0]\n",
    "minor_y = y[y == 1]\n",
    "major_y = y[y == 0]\n",
    "\n",
    "minority_upsampled_X = resample(\n",
    "    minor_X, replace=True, n_samples=major_X.shape[0], random_state=123)\n",
    "minority_upsampled_y = resample(\n",
    "    minor_y, replace=True, n_samples=major_X.shape[0], random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "resampled_X = pd.concat([major_X, minority_upsampled_X])\n",
    "resampled_y = pd.concat([major_y, minority_upsampled_y])\n",
    "\n",
    "normalized_resampled_X = scaler.transform(resampled_X)\n",
    "\n",
    "train_X, train_y, validation_X, validation_y = train_test_split(\n",
    "    *shuffle(normalized_resampled_X, resampled_y, random_state=0), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Could not interpret metric function identifier:', <__main__.roc_callback object at 0x7fcd224f1748>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-75b4df6cc3b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m model.compile(\n\u001b[1;32m     47\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroc_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m )\n",
      "\u001b[0;32m~/workspace/proj/dyzsasd.github.io/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0moutput_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0moutput_weighted_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_weighted_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/proj/dyzsasd.github.io/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    406\u001b[0m                     \u001b[0mmetric_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_name_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                     \u001b[0mmetric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                     \u001b[0mweighted_metric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_masked_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                     \u001b[0;31m# Get metric name as string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/proj/dyzsasd.github.io/env/lib/python3.6/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         raise ValueError('Could not interpret '\n\u001b[0;32m---> 83\u001b[0;31m                          'metric function identifier:', identifier)\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: ('Could not interpret metric function identifier:', <__main__.roc_callback object at 0x7fcd224f1748>)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self, training_data, validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, input_shape=(200, ),activation= 'relu'),\n",
    "    Dense(128, activation= 'relu'),\n",
    "    Dense(32, activation= 'relu'),\n",
    "    Dropout(.6),\n",
    "    Dense(1, activation= 'sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'Adam', loss = 'binary_crossentropy',\n",
    "    metrics= [roc_callback(training_data=(train_X, train_y), validation_data=(validation_X, validation_y))]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "359804/359804 [==============================] - 1s 4us/step - loss: 0.5741 - acc: 0.6963\n",
      "Epoch 2/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.4823 - acc: 0.7764\n",
      "Epoch 3/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.4540 - acc: 0.7899\n",
      "Epoch 4/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.4155 - acc: 0.8115\n",
      "Epoch 5/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.3555 - acc: 0.8515\n",
      "Epoch 6/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.2916 - acc: 0.8898\n",
      "Epoch 7/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.2398 - acc: 0.9170\n",
      "Epoch 8/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.2034 - acc: 0.9344\n",
      "Epoch 9/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.1670 - acc: 0.9502\n",
      "Epoch 10/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.1408 - acc: 0.9609\n",
      "Epoch 11/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.1257 - acc: 0.9652\n",
      "Epoch 12/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.1032 - acc: 0.9740\n",
      "Epoch 13/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0875 - acc: 0.9785\n",
      "Epoch 14/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0786 - acc: 0.9808\n",
      "Epoch 15/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0654 - acc: 0.9846\n",
      "Epoch 16/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0534 - acc: 0.9881\n",
      "Epoch 17/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0452 - acc: 0.9901\n",
      "Epoch 18/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0381 - acc: 0.9918\n",
      "Epoch 19/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0333 - acc: 0.9927\n",
      "Epoch 20/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0312 - acc: 0.9931\n",
      "Epoch 21/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0266 - acc: 0.9940\n",
      "Epoch 22/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0213 - acc: 0.9955\n",
      "Epoch 23/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0209 - acc: 0.9953\n",
      "Epoch 24/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0187 - acc: 0.9957\n",
      "Epoch 25/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0201 - acc: 0.9949\n",
      "Epoch 26/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.2896 - acc: 0.9019\n",
      "Epoch 27/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0882 - acc: 0.9722\n",
      "Epoch 28/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0268 - acc: 0.9937\n",
      "Epoch 29/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0158 - acc: 0.9969\n",
      "Epoch 30/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0115 - acc: 0.9981\n",
      "Epoch 31/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0096 - acc: 0.9986\n",
      "Epoch 32/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0080 - acc: 0.9989\n",
      "Epoch 33/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0071 - acc: 0.9991\n",
      "Epoch 34/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0062 - acc: 0.9992\n",
      "Epoch 35/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0055 - acc: 0.9993\n",
      "Epoch 36/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0052 - acc: 0.9994\n",
      "Epoch 37/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0048 - acc: 0.9994\n",
      "Epoch 38/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0047 - acc: 0.9994\n",
      "Epoch 39/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0046 - acc: 0.9994\n",
      "Epoch 40/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0043 - acc: 0.9995\n",
      "Epoch 41/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0041 - acc: 0.9995\n",
      "Epoch 42/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0040 - acc: 0.9995\n",
      "Epoch 43/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0038 - acc: 0.9996\n",
      "Epoch 44/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 45/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0037 - acc: 0.9996\n",
      "Epoch 46/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 47/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0039 - acc: 0.9995\n",
      "Epoch 48/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0038 - acc: 0.9995\n",
      "Epoch 49/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0041 - acc: 0.9994\n",
      "Epoch 50/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0043 - acc: 0.9994\n",
      "Epoch 51/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0048 - acc: 0.9991\n",
      "Epoch 52/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0073 - acc: 0.9984\n",
      "Epoch 53/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0112 - acc: 0.9970\n",
      "Epoch 54/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0176 - acc: 0.9951\n",
      "Epoch 55/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0173 - acc: 0.9953\n",
      "Epoch 56/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0159 - acc: 0.9957\n",
      "Epoch 57/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0132 - acc: 0.9965\n",
      "Epoch 58/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0124 - acc: 0.9968\n",
      "Epoch 59/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0098 - acc: 0.9977\n",
      "Epoch 60/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0078 - acc: 0.9982A: 0s - loss: 0.0069 - \n",
      "Epoch 61/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0071 - acc: 0.9984\n",
      "Epoch 62/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0068 - acc: 0.9985\n",
      "Epoch 63/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0060 - acc: 0.9987\n",
      "Epoch 64/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0052 - acc: 0.9989\n",
      "Epoch 65/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0043 - acc: 0.9992\n",
      "Epoch 66/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0039 - acc: 0.9993\n",
      "Epoch 67/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 68/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0045 - acc: 0.9991\n",
      "Epoch 69/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0040 - acc: 0.9992\n",
      "Epoch 70/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 71/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0034 - acc: 0.9994\n",
      "Epoch 72/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0043 - acc: 0.9991\n",
      "Epoch 73/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0059 - acc: 0.9986\n",
      "Epoch 74/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0071 - acc: 0.9983\n",
      "Epoch 75/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0126 - acc: 0.9965\n",
      "Epoch 76/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0149 - acc: 0.9958\n",
      "Epoch 77/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0102 - acc: 0.9974\n",
      "Epoch 78/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0102 - acc: 0.9973\n",
      "Epoch 79/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0117 - acc: 0.9969\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0092 - acc: 0.9976\n",
      "Epoch 81/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0076 - acc: 0.9982\n",
      "Epoch 82/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0051 - acc: 0.9989\n",
      "Epoch 83/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0065 - acc: 0.9983\n",
      "Epoch 84/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0060 - acc: 0.9986\n",
      "Epoch 85/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0054 - acc: 0.9987\n",
      "Epoch 86/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0049 - acc: 0.9988\n",
      "Epoch 87/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0048 - acc: 0.9990\n",
      "Epoch 88/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0041 - acc: 0.9991\n",
      "Epoch 89/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0057 - acc: 0.9986\n",
      "Epoch 90/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 91/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0070 - acc: 0.9982\n",
      "Epoch 92/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0065 - acc: 0.9983\n",
      "Epoch 93/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0064 - acc: 0.9984\n",
      "Epoch 94/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0056 - acc: 0.9986\n",
      "Epoch 95/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0063 - acc: 0.9985\n",
      "Epoch 96/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0066 - acc: 0.9983\n",
      "Epoch 97/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0049 - acc: 0.9988\n",
      "Epoch 98/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0050 - acc: 0.9988\n",
      "Epoch 99/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0067 - acc: 0.9983\n",
      "Epoch 100/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0053 - acc: 0.9987\n",
      "Epoch 101/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 102/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 103/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0045 - acc: 0.9989\n",
      "Epoch 104/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0039 - acc: 0.9991\n",
      "Epoch 105/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0041 - acc: 0.9990\n",
      "Epoch 106/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 107/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0052 - acc: 0.9988\n",
      "Epoch 108/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0048 - acc: 0.9988\n",
      "Epoch 109/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 110/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0050 - acc: 0.9988\n",
      "Epoch 111/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0054 - acc: 0.9986\n",
      "Epoch 112/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 113/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0055 - acc: 0.9986\n",
      "Epoch 114/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0050 - acc: 0.9988\n",
      "Epoch 115/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0040 - acc: 0.9991\n",
      "Epoch 116/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0063 - acc: 0.9982\n",
      "Epoch 117/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0057 - acc: 0.9986\n",
      "Epoch 118/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0058 - acc: 0.9986\n",
      "Epoch 119/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0044 - acc: 0.9989\n",
      "Epoch 120/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 121/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 122/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0041 - acc: 0.9990\n",
      "Epoch 123/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0036 - acc: 0.9992\n",
      "Epoch 124/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 125/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0047 - acc: 0.9988\n",
      "Epoch 126/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0047 - acc: 0.9988\n",
      "Epoch 127/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0045 - acc: 0.9988\n",
      "Epoch 128/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 129/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0032 - acc: 0.9993\n",
      "Epoch 130/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0042 - acc: 0.9989\n",
      "Epoch 131/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0041 - acc: 0.9990\n",
      "Epoch 132/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0036 - acc: 0.9992\n",
      "Epoch 133/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0056 - acc: 0.9985\n",
      "Epoch 134/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 135/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0042 - acc: 0.9989\n",
      "Epoch 136/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0039 - acc: 0.9990\n",
      "Epoch 137/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0039 - acc: 0.9990\n",
      "Epoch 138/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 139/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 140/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 141/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0053 - acc: 0.9987\n",
      "Epoch 142/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 143/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0046 - acc: 0.9987\n",
      "Epoch 144/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0045 - acc: 0.9989\n",
      "Epoch 145/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 146/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0036 - acc: 0.9991\n",
      "Epoch 147/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0034 - acc: 0.9992\n",
      "Epoch 148/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 149/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0045 - acc: 0.9988\n",
      "Epoch 150/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0038 - acc: 0.9991\n",
      "Epoch 151/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0034 - acc: 0.9992\n",
      "Epoch 152/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 153/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0039 - acc: 0.9990\n",
      "Epoch 154/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 155/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 156/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 157/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 158/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0026 - acc: 0.9994\n",
      "Epoch 160/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 161/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 162/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 163/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0034 - acc: 0.9991\n",
      "Epoch 164/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 165/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 166/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0060 - acc: 0.9983\n",
      "Epoch 167/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0258 - acc: 0.9914\n",
      "Epoch 168/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 169/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 7.2846e-04 - acc: 0.9999\n",
      "Epoch 170/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 6.0317e-04 - acc: 1.0000\n",
      "Epoch 171/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 5.3206e-04 - acc: 1.0000\n",
      "Epoch 172/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 5.4737e-04 - acc: 1.0000\n",
      "Epoch 173/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 5.2090e-04 - acc: 1.0000\n",
      "Epoch 174/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 5.0242e-04 - acc: 1.0000\n",
      "Epoch 175/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.8780e-04 - acc: 1.0000\n",
      "Epoch 176/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.7740e-04 - acc: 1.0000\n",
      "Epoch 177/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.9570e-04 - acc: 1.0000\n",
      "Epoch 178/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.9094e-04 - acc: 1.0000\n",
      "Epoch 179/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.8813e-04 - acc: 1.0000\n",
      "Epoch 180/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.1232e-04 - acc: 1.0000\n",
      "Epoch 181/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.6044e-04 - acc: 1.0000\n",
      "Epoch 182/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.5984e-04 - acc: 1.0000\n",
      "Epoch 183/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.3129e-04 - acc: 1.0000\n",
      "Epoch 184/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 7.4579e-04 - acc: 0.9999\n",
      "Epoch 185/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0092 - acc: 0.9979\n",
      "Epoch 186/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0132 - acc: 0.9960\n",
      "Epoch 187/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 188/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 189/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 190/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0044 - acc: 0.9988\n",
      "Epoch 191/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0041 - acc: 0.9989\n",
      "Epoch 192/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0047 - acc: 0.9987\n",
      "Epoch 193/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 194/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 195/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 196/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 197/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 198/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 199/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0031 - acc: 0.9992\n",
      "Epoch 200/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 201/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 202/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0047 - acc: 0.9986\n",
      "Epoch 203/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 204/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 205/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 206/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 207/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 208/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 209/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 210/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 211/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 212/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 213/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0057 - acc: 0.9985\n",
      "Epoch 214/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 215/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 216/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 217/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 218/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 219/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 220/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0022 - acc: 0.9995\n",
      "Epoch 221/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 222/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0041 - acc: 0.9988\n",
      "Epoch 223/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 224/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 225/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 226/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 227/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 228/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0944 - acc: 0.9705\n",
      "Epoch 229/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0471 - acc: 0.9850\n",
      "Epoch 230/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0054 - acc: 0.9988\n",
      "Epoch 231/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 232/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 7.5751e-04 - acc: 0.9999\n",
      "Epoch 233/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 5.3912e-04 - acc: 0.9999\n",
      "Epoch 234/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 5.0204e-04 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.7083e-04 - acc: 0.9999\n",
      "Epoch 236/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.1580e-04 - acc: 1.0000\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.9522e-04 - acc: 0.9999\n",
      "Epoch 238/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.9098e-04 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.6536e-04 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.3000e-04 - acc: 0.9999\n",
      "Epoch 241/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.8918e-04 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.2422e-04 - acc: 0.9999\n",
      "Epoch 243/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 4.2310e-04 - acc: 0.9999\n",
      "Epoch 244/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.8627e-04 - acc: 0.9999\n",
      "Epoch 245/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.7017e-04 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.5139e-04 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.5871e-04 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.2219e-04 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.4150e-04 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.1777e-04 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.2552e-04 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.3242e-04 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.1289e-04 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.4283e-04 - acc: 1.0000\n",
      "Epoch 255/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.2762e-04 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.6307e-04 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.4004e-04 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.3912e-04 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.5865e-04 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.7480e-04 - acc: 0.9999\n",
      "Epoch 261/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.2692e-04 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.1075e-04 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.2863e-04 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.3228e-04 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.2831e-04 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.3726e-04 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.7234e-04 - acc: 0.9999\n",
      "Epoch 268/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 3.2692e-04 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 5.8981e-04 - acc: 0.9999\n",
      "Epoch 270/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 271/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 272/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 273/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0055 - acc: 0.9985\n",
      "Epoch 274/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 275/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 276/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 277/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0031 - acc: 0.9992\n",
      "Epoch 278/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 279/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 280/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 281/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 282/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0038 - acc: 0.9989\n",
      "Epoch 283/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 284/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 285/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 286/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 287/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0033 - acc: 0.9991\n",
      "Epoch 288/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 289/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 290/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 291/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 292/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 293/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 294/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 295/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0049 - acc: 0.9986\n",
      "Epoch 296/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 297/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 298/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 299/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 300/300\n",
      "359804/359804 [==============================] - 1s 2us/step - loss: 0.0023 - acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53ed679208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, validation_split=0, epochs=300, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "0  18.2675  2.1337   ...     -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
       "1  18.6316 -4.4131   ...     10.6165   8.8349   0.9403  10.1282  15.5765   \n",
       "2  20.2537  1.5233   ...     -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
       "3  20.5660  3.3755   ...      9.5702   9.0766   1.6580   3.5813  15.1874   \n",
       "4  10.6048  2.9890   ...      4.2259   9.1723   1.2835   3.3778  19.5542   \n",
       "\n",
       "   var_195  var_196  var_197  var_198  var_199  \n",
       "0   2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
       "1   0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2   2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = scaler.transform(data[data.columns.difference(['ID_code', 'target'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = model.predict_classes(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = list(zip(test_data['ID_code'], test_y[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2688889"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fout = open('submission.csv', 'w')\n",
    "\n",
    "fout.write('ID_code,target\\n')\n",
    "fout.write('\\n'.join(['%s,%s' % item for item in submission]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
